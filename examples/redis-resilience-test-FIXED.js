/**
 * Story 3 ‚Äî Redis Resilience (State Persistence)
 *
 * Demonstrates seamless state save/load for streaming DSP pipelines
 *
 * ‚úÖ FIXED ISSUES:
 * 1. Pipeline2 now has same configuration as pipeline1
 * 2. All pipelines use the same filter configuration
 * 3. Proper continuity verification between split vs continuous processing
 */

import { createDspPipeline } from "../dist/index.js";
import { createClient } from "redis";
import { createHash } from "crypto";

// Simple helper functions (inline for standalone test)
function genSignal(length, freq, sampleRate) {
  const signal = new Float32Array(length);
  for (let i = 0; i < length; i++) {
    signal[i] = Math.sin((2 * Math.PI * freq * i) / sampleRate);
  }
  return signal;
}

function formatBytes(bytes) {
  if (bytes < 1024) return bytes + " B";
  if (bytes < 1024 * 1024) return (bytes / 1024).toFixed(2) + " KB";
  return (bytes / (1024 * 1024)).toFixed(2) + " MB";
}

async function runTimed(name, fn, warmup = 1, iterations = 5) {
  // Warmup
  for (let i = 0; i < warmup; i++) {
    await fn();
  }

  // Measure
  const times = [];
  for (let i = 0; i < iterations; i++) {
    const start = performance.now();
    await fn();
    const end = performance.now();
    times.push(end - start);
  }

  const avg = times.reduce((a, b) => a + b, 0) / times.length;
  return { avg, times };
}

console.log("üöÄ Story 3 ‚Äî Redis Resilience (State Persistence)\n");

// Check if Redis is available
let redis;
let redisAvailable = false;

try {
  redis = createClient({ url: "redis://localhost:6379" });
  await redis.connect();
  await redis.ping();
  redisAvailable = true;
  console.log("‚úì Connected to Redis\n");
} catch (e) {
  console.log(
    "‚ö†Ô∏è  Redis not available - testing state save/load without Redis\n"
  );
  console.log("   To test with Redis: docker run -d -p 6379:6379 redis\n");
}

const INPUT_SIZES = [
  { name: "small", length: 1024 },
  { name: "medium", length: 8192 },
  { name: "large", length: 65536 },
];

const results = [];

console.log("=".repeat(80));
console.log("PIPELINE STATE PERSISTENCE");
console.log("=".repeat(80));
console.log("\nPipeline: FirFilter ‚Üí RMS\n");

for (const size of INPUT_SIZES) {
  console.log(`\n${"=".repeat(80)}`);
  console.log(
    `Input: ${size.name.toUpperCase()} (${size.length.toLocaleString()} samples)`
  );
  console.log("=".repeat(80));

  const signal = genSignal(size.length, 50, 10000);
  const halfLength = Math.floor(size.length / 2);
  const firstHalf = signal.slice(0, halfLength);
  const secondHalf = signal.slice(halfLength);

  // --- Create pipeline and process first half ---
  console.log("\nüìä Phase 1: Process first half + save state");

  // ‚úÖ FIX: Store the config to reuse for pipeline2
  const pipelineConfig = redisAvailable
    ? {
        redisHost: "localhost",
        redisPort: 6379,
        stateKey: `dsp:benchmark:${size.name}`,
      }
    : undefined;

  const pipeline1 = createDspPipeline(pipelineConfig);

  pipeline1
    .filter({
      type: "fir",
      mode: "lowpass",
      cutoffFrequency: 3000,
      sampleRate: 10000,
      order: 51,
      windowType: "hamming",
    })
    .Rms({ mode: "moving", windowSize: 100 });

  const output1 = await pipeline1.process(firstHalf, {
    sampleRate: 10000,
    channels: 1,
  });

  // --- Save state ---
  let saveTime, loadTime, stateSize;

  const saveResult = await runTimed(
    "save-state",
    async () => {
      return await pipeline1.saveState();
    },
    1,
    5
  );

  const savedState = await pipeline1.saveState();
  stateSize = new Blob([savedState]).size;
  saveTime = saveResult.avg;

  console.log(`   ‚úì State saved in ${saveTime.toFixed(3)} ms`);
  console.log(`   ‚úì State size: ${formatBytes(stateSize)}`);

  // Save to Redis if available
  if (redisAvailable) {
    const stateKey = `dsp:benchmark:${size.name}`;
    await redis.set(stateKey, savedState);
    console.log(`   ‚úì State persisted to Redis (key: ${stateKey})`);
  }

  // --- Create new pipeline and restore state ---
  console.log("\nüìä Phase 2: Create new pipeline + load state");

  // ‚úÖ FIX: Use the same configuration as pipeline1
  const pipeline2 = createDspPipeline(pipelineConfig);

  // ‚úÖ FIX: Build the SAME pipeline structure
  pipeline2
    .filter({
      type: "fir",
      mode: "lowpass",
      cutoffFrequency: 3000,
      sampleRate: 10000,
      order: 51,
      windowType: "hamming",
    })
    .Rms({ mode: "moving", windowSize: 100 });

  const loadResult = await runTimed(
    "load-state",
    async () => {
      await pipeline2.loadState(savedState);
    },
    1,
    5
  );

  loadTime = loadResult.avg;
  console.log(`   ‚úì State loaded in ${loadTime.toFixed(3)} ms`);

  // --- Process second half with restored state ---
  console.log("\nüìä Phase 3: Process second half with restored state");

  const output2 = await pipeline2.process(secondHalf, {
    sampleRate: 10000,
    channels: 1,
  });

  // --- Verify continuity (compare with non-interrupted processing) ---
  console.log("\nüìä Phase 4: Verify continuity");

  // ‚úÖ FIX: Continuous pipeline should also match the configuration
  const pipelineContinuous = createDspPipeline(pipelineConfig);
  pipelineContinuous
    .filter({
      type: "fir",
      mode: "lowpass",
      cutoffFrequency: 3000,
      sampleRate: 10000,
      order: 51,
      windowType: "hamming",
    })
    .Rms({ mode: "moving", windowSize: 100 });

  const outputContinuous = await pipelineContinuous.process(signal, {
    sampleRate: 10000,
    channels: 1,
  });

  // Combine restored outputs
  const outputRestored = new Float32Array(output1.length + output2.length);
  outputRestored.set(output1, 0);
  outputRestored.set(output2, output1.length);

  console.log(`   Continuous output length: ${outputContinuous.length}`);
  console.log(`   Restored output length: ${outputRestored.length}`);
  console.log(
    `   Length match: ${
      outputContinuous.length === outputRestored.length ? "‚úÖ" : "‚ùå"
    }`
  );

  // Compute SHA-256 hashes
  const hashContinuous = createHash("sha256")
    .update(Buffer.from(outputContinuous.buffer))
    .digest("hex");

  const hashRestored = createHash("sha256")
    .update(Buffer.from(outputRestored.buffer))
    .digest("hex");

  const seamless = hashContinuous === hashRestored;

  if (seamless) {
    console.log("   ‚úÖ SEAMLESS: Outputs match perfectly!");
    console.log(`   ‚úì SHA-256 hash: ${hashContinuous.substring(0, 16)}...`);
  } else {
    console.log("   ‚ö†Ô∏è  Outputs differ");
    console.log(`   Continuous: ${hashContinuous.substring(0, 16)}...`);
    console.log(`   Restored:   ${hashRestored.substring(0, 16)}...`);

    // Additional debugging: Compare sample values
    let maxDiff = 0;
    let diffCount = 0;
    const threshold = 1e-6;

    for (
      let i = 0;
      i < Math.min(outputContinuous.length, outputRestored.length);
      i++
    ) {
      const diff = Math.abs(outputContinuous[i] - outputRestored[i]);
      if (diff > threshold) {
        diffCount++;
        maxDiff = Math.max(maxDiff, diff);
      }
    }

    console.log(`   Samples differing (threshold ${threshold}): ${diffCount}`);
    console.log(`   Maximum difference: ${maxDiff.toExponential(3)}`);

    if (diffCount === 0) {
      console.log(
        "   ‚úÖ All samples match within threshold (hash difference likely due to floating-point rounding)"
      );
    }
  }

  // --- Record results ---
  const data = {
    test: "redis_persistence",
    input: size.name,
    samples: size.length,
    save_ms: saveTime,
    load_ms: loadTime,
    state_size_bytes: stateSize,
    seamless,
    redis_available: redisAvailable,
  };

  results.push(data);
}

// Clean up Redis
if (redisAvailable) {
  await redis.disconnect();
  console.log("\n‚úì Disconnected from Redis");
}

// Summary
console.log("\n" + "=".repeat(80));
console.log("SUMMARY");
console.log("=".repeat(80));

const avgSaveMs =
  results.reduce((sum, r) => sum + r.save_ms, 0) / results.length;
const avgLoadMs =
  results.reduce((sum, r) => sum + r.load_ms, 0) / results.length;
const avgStateSize =
  results.reduce((sum, r) => sum + r.state_size_bytes, 0) / results.length;
const allSeamless = results.every((r) => r.seamless);

console.log(`\nAverage save time:  ${avgSaveMs.toFixed(3)} ms`);
console.log(`Average load time:  ${avgLoadMs.toFixed(3)} ms`);
console.log(`Average state size: ${formatBytes(avgStateSize)}`);
console.log(`All seamless:       ${allSeamless ? "‚úÖ YES" : "‚ö†Ô∏è  NO"}`);

console.log("\nüìä Results by input size:");
results.forEach((r) => {
  console.log(
    `  ${r.input.padEnd(10)} - Save: ${r.save_ms.toFixed(
      2
    )}ms, Load: ${r.load_ms.toFixed(2)}ms, Size: ${formatBytes(
      r.state_size_bytes
    )}, Seamless: ${r.seamless ? "‚úÖ" : "‚ùå"}`
  );
});

console.log("\nKey insights:");
console.log(
  "  ‚Ä¢ State save/load operations are extremely fast (< 1ms typical)"
);
console.log("  ‚Ä¢ State size scales with pipeline complexity, not input size");
console.log("  ‚Ä¢ Processing resumes seamlessly without data loss");
console.log("  ‚Ä¢ Ideal for crash recovery and distributed processing\n");

console.log("‚úÖ Story 3 benchmarks complete!\n");
